# -*- coding: utf-8 -*-
"""LANGCHAIN MODELS

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hGDSQutT_ITL41-RtdrgH_wbLqA2GPGQ
"""

from google.colab import files
files.upload()

"""# requirements.txt
### LangChain Core
langchain
langchain-core

### OpenAI Integration
langchain-openai
openai

### Anthropic Integration
langchain-anthropic

### Google Gemini (PaLM) Integration
langchain-google-genai
google-generativeai

### Hugging Face Integration
langchain-huggingface
transformers
huggingface-hub

### Machine Learning Utilities
numpy
scikit-learn
"""

!pip install -r requirements.txt

"""# 1) LLM's"""

from google.colab import files
files.upload()

!pip install -q langchain-google-genai google-generativeai

from langchain_google_genai import ChatGoogleGenerativeAI

!mv ".env (1)" .env
!ls -a

from dotenv import load_dotenv
import os
load_dotenv()
print(os.getenv("GOOGLE_API_KEY"))

model = ChatGoogleGenerativeAI(model = 'gemini-2.5-flash' ,temperature=0.9 )
result = model.invoke("Who is Virat Kohli")
print(result)

"""# OPEN SOURCE MODELS
https://huggingface.co/models
"""

from google.colab import files
files.upload()

!pip uninstall -y langchain langchain-core langchain-huggingface langchain-openai langchain-google-genai langchain-anthropic langchain_community || true

!pip install -q "langchain-core<1.0.0"
!pip install -q langchain langchain-huggingface langchain-openai langchain-google-genai langchain-anthropic transformers huggingface_hub

!pip uninstall -y google-generativeai google-ai-generativelanguage langchain langchain-core langchain-huggingface langchain-openai langchain-google-genai langchain-anthropic transformers huggingface_hub

!pip install -q "langchain-core<1.0.0"
!pip install -q langchain langchain-huggingface langchain-openai langchain-anthropic transformers huggingface_hub

try:
    from langchain_community.llms.huggingface_endpoint import HuggingFaceEndpoint
    from langchain_community.chat_models.huggingface import ChatHuggingFace
except ImportError:
    from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace

llm = HuggingFaceEndpoint(
    repo_id="mistralai/Mixtral-8x7B-Instruct-v0.1",
    task="conversational",
    temperature=0.9
)
chat = ChatHuggingFace(llm=llm)
response = chat.invoke("Who is Virat Kohli?")
print(response)

"""# Importing model from HF instead of USING API

"""

from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline
llm = HuggingFacePipeline.from_model_id(
    model_id = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0',
    task = 'text-generation',
    pipeline_kwargs = dict(
        temperature = 0.7,
        max_new_tokens = 100
    )
)
model = ChatHuggingFace(llm=llm)
result = model.invoke("Who is Virat Kohli")
print(result)

"""# EMBEDDING MODELS"""

from langchain_huggingface import HuggingFaceEmbeddings
embedding = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')
text = 'Hi How Are You'
vector = embedding.embed_query(text)
print(str(vector))

documents = ['Delhi is capital of India',
             'Kolkata is the capital of West Bengal',
             'Paris is capital of France']
vectors = embedding.embed_documents(documents)
print(str(vectors))

"""# DOCUMENT SEARCH SIMILARITY"""

from langchain_huggingface import HuggingFaceEmbeddings
from dotenv import load_dotenv
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

load_dotenv()
embedding = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')

documents = [
    "Virat Kohli is an Indian cricketer known for his aggressive batting and leadership.",
    "MS Dhoni is a former Indian captain famous for his calm demeanor and finishing skills.",
    "Sachin Tendulkar, also known as the 'God of Cricket', holds many batting records.",
    "Rohit Sharma is known for his elegant batting and record-breaking double centuries.",
    "Jasprit Bumrah is an Indian fast bowler known for his unorthodox action and yorkers."
]

query1 = 'tell me about Ms Dhoni'

docEmbeddings = embedding.embed_documents(documents)
query1Embeddings = embedding.embed_query(query1)

'For Cosine Similarity We need to send 2D List'
similarity1 = cosine_similarity([query1Embeddings], docEmbeddings)[0]
index, score = sorted(list(enumerate(similarity1)), key = lambda x:x[1])[-1]

print(query1)
print(documents[index])
print("Similarity Score:" ,score)

"""* By default Vector Dimension in 384"""