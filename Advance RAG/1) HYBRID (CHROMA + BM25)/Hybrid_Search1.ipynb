{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "azTxEOvje0ju"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"This is a list which containing sample documents.\",\n",
        "    \"Keywords are important for keyword-based search.\",\n",
        "    \"Document analysis involves extracting keywords,\",\n",
        "    \"Keyword-based search relies on sparse embeddings.\"\n",
        "]"
      ],
      "metadata": {
        "id": "P6XYSFFZgDrI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"keyword-based search\""
      ],
      "metadata": {
        "id": "BaPxuWyJhxsG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def preprocess(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'[^\\w\\s]', '', text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "c4j8ZbTCh2yX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessedQuery = preprocess(query)\n",
        "preprocessedQuery"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lUe2qiealLke",
        "outputId": "52de57ed-5b65-49c0-b3b7-d02bd443a616"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'keywordbased search'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preproceesed = [preprocess(doc) for doc in documents]\n",
        "preproceesed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-qKr4WBkgyT",
        "outputId": "f44216b3-fc7c-4bf9-d0d4-13be10749714"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this is a list which containing sample documents',\n",
              " 'keywords are important for keywordbased search',\n",
              " 'document analysis involves extracting keywords',\n",
              " 'keywordbased search relies on sparse embeddings']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = TfidfVectorizer()\n",
        "x = vector.fit_transform(preproceesed)\n",
        "x.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR79M3yAlQ-A",
        "outputId": "a66fc023-e5a6-463c-c6e9-5f9a79eeaea0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.37796447, 0.        , 0.37796447,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.37796447, 0.        , 0.        , 0.37796447, 0.        ,\n",
              "        0.        , 0.37796447, 0.        , 0.        , 0.37796447,\n",
              "        0.37796447],\n",
              "       [0.        , 0.4533864 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.4533864 , 0.4533864 , 0.        ,\n",
              "        0.        , 0.35745504, 0.35745504, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.35745504, 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.46516193, 0.        , 0.        , 0.46516193, 0.        ,\n",
              "        0.        , 0.46516193, 0.        , 0.        , 0.46516193,\n",
              "        0.        , 0.        , 0.36673901, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.43671931, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34431452, 0.        , 0.        , 0.43671931,\n",
              "        0.43671931, 0.        , 0.34431452, 0.43671931, 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axkDH35Tn0vW",
        "outputId": "f69405f4-fad0-4530-c11e-aadb4e4edac5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['analysis', 'are', 'containing', 'document', 'documents',\n",
              "       'embeddings', 'extracting', 'for', 'important', 'involves', 'is',\n",
              "       'keywordbased', 'keywords', 'list', 'on', 'relies', 'sample',\n",
              "       'search', 'sparse', 'this', 'which'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.toarray()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdiPqAzwlaJJ",
        "outputId": "c25ca652-a9b9-4b2f-fbfc-f0a858f62a05"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.37796447, 0.        , 0.37796447,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.37796447, 0.        , 0.        , 0.37796447, 0.        ,\n",
              "       0.        , 0.37796447, 0.        , 0.        , 0.37796447,\n",
              "       0.37796447])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddedQuery = vector.transform([preprocessedQuery])\n",
        "embeddedQuery.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8plFg6TmJAS",
        "outputId": "a1529412-bd8d-4ba6-89f5-bf5285d9651e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.70710678, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.70710678, 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity = cosine_similarity(x, embeddedQuery)\n",
        "similarity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHRsOsUztDFN",
        "outputId": "00f35afc-f449-4b11-a2cc-fd31ecca3fa8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        ],\n",
              "       [0.50551777],\n",
              "       [0.        ],\n",
              "       [0.48693426]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argsort(similarity, axis = 0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa4CHbQ3t8tY",
        "outputId": "5d109f7d-ebd8-4092-9140-621fccff67f8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [2],\n",
              "       [3],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rankedIndices = np.argsort(similarity, axis=0)[::-1].flatten()"
      ],
      "metadata": {
        "id": "F3O769iatumK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rankedIndices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agy85mUDt5Ms",
        "outputId": "40e045fa-9ec7-4d33-94d4-5e978aa7856b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 2, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rankedDocs = [documents[i] for i in rankedIndices]"
      ],
      "metadata": {
        "id": "KY2EJBwCwKLy"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, doc in enumerate(rankedDocs):\n",
        "  print(f\"Rank {i+1}: {doc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdD9A2lcwSrF",
        "outputId": "46ecedc3-b667-49d8-f362-84108a2f12dc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank 1: Keywords are important for keyword-based search.\n",
            "Rank 2: Keyword-based search relies on sparse embeddings.\n",
            "Rank 3: Document analysis involves extracting keywords,\n",
            "Rank 4: This is a list which containing sample documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Langchain"
      ],
      "metadata": {
        "id": "L6Ymebdj2KCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/1.pdf\""
      ],
      "metadata": {
        "id": "DoXSixXn2JmL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pypdf\n",
        "%pip install langchain_community"
      ],
      "metadata": {
        "id": "lZUzcbVS2TqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "BncoZd7x3HvJ",
        "outputId": "eaab0aab-2a4c-4ab8-c5c1-1918a3946912"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e0431b63-3cb5-48e3-bc30-ba5cfdb90594\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e0431b63-3cb5-48e3-bc30-ba5cfdb90594\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1.pdf to 1.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(path)"
      ],
      "metadata": {
        "id": "ApQgnl2F2X8j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "2zcW_9LS2om_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0tF6a_73Vhn",
        "outputId": "f55684d4-2b0f-4dc4-8979-61adaf75acdd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.4)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.7)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.6.4)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.13.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.6)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=30)\n",
        "chunks = splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "2pdVvcLK23r4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain-huggingface"
      ],
      "metadata": {
        "id": "ddNBA4DH3pE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embedding = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "3508908ab8c24163a17a1b379b0ca759",
            "0add5368fa2c478296fbf44b6179ddeb",
            "0234755a4d0b4941a2f0e703e9bcd89a",
            "c58deadc6f6043cda640dfbddc9bff3c",
            "667a239bf2d3473b9abce55d07930fd6",
            "e56a5efe2e964c37974200c4024cb678",
            "392302e2752942b6a5a98b01e5925023",
            "14d157c994be4b48a89e58a8dc1d20ae",
            "bbfd2bed783e478dbdb5c814713f886d",
            "5750dda8cad544dabfeb44e84d5b0922",
            "baebe606d2bd4310b7f34681bf10da2b",
            "fb0b08915b4a4e82a85b2ffa7c03baa7",
            "5ec5d8cab91d49e4891a7343dbdbd28d",
            "ab647e93124b4479b3b609b176aa5210",
            "5cac376eafc04b3994824e8501a55b13",
            "c3e33695ae4947da964b5d3105e95897",
            "348ba4f5f5e44acea9c8afd4aa4e90f5",
            "fe57ef1b34d442adba3af7761df49245",
            "d547612e0e794936887a87647fb836f0",
            "eb0095916d4b412dbda4a1685609f6ef",
            "c88ce0e94012466ebb4af559013e3f5d",
            "ed752724ab1846aab165222e7f8c05cc",
            "145fdebe9d2a48f2a42b3fc32b2f49f4",
            "6841d9a6986a45e99bb6ac01677b2eda",
            "30bf3e6fe0474846bc0fbce3daeb3120",
            "7ac304475cca4edda42e3ff7477e8b52",
            "0341d6e2786f4330851603040d673fec",
            "5ee9deace0074338a27afc25b9e8a357",
            "7c34268ce0c34d87913f38e71feaa4c4",
            "b4065726baed4e9aa3463c0a17adfc3b",
            "13719316e8e0439d936b2eabaab97bf8",
            "0e0057456bcc4e698768be88b49e8aab",
            "454b3bd365b94319a608dd190827a85c",
            "c78356fdae574ac080ca58b5956a8153",
            "4ec231ee868f451db2edfa27a426f14f",
            "c18fa95e797146589cef84a1fa62e0aa",
            "e8ab03bc8d60428b90bd7617d5f27a9a",
            "20a0b7425f2c495eadd497740c6da9b9",
            "c239fe111896470db5beb341d332a3c9",
            "d643415438444617b407ba79fdcdcc3e",
            "98dc75edbb3d44d19b22888e52b67ddb",
            "c8e9b65d0bfd428da576285276bddada",
            "69cf897d5ff94795aea54175fe3b82a6",
            "1970bc4591e242e89353854d24ad96d7",
            "2887979cbd914f089f2566f83575191d",
            "a84cbbb580e4445790c6989c25038005",
            "42441d5971bc4977a6848238e0f014c5",
            "32ea0f564cd74412a7b3b5ef690aefab",
            "b9edd9549ae74cbda065b850f1fa8af6",
            "ed86440cc39746bcbc92e34a458d518a",
            "29806dcb83564355bd4b260dbb48a6f7",
            "8af0b9c2649e4ecbaf53fd3ebb4d579b",
            "510fcc68d608463a962dc6d1d61f34bc",
            "3b577cdc9d9a4585b8ce4c6f47bf6fb3",
            "623c076be61e41c0beca3c1815598433",
            "679f3f024cd347b79ddb1ce0722f49c8",
            "cdd6b1ee44a44ae68263ff8faf253efc",
            "b730264f91bb4be395a59522a5c536b3",
            "1e22044f11574aafb0dde914bbf7af00",
            "42252d44638f439da64e0cccbec77006",
            "6a089d3afc4e4e87b4a8e68844b365d4",
            "b3f53a7a41444ab189e4ab8a99658e0f",
            "fa2e3f4cc81b41e783fa5bef3534a8f3",
            "2d296d26b85f404fbad125d0e2acd325",
            "0f1e4256bed04d47ac75eb00fc7c9d27",
            "74b9a6ad8f284a2b8e5ec2e61a8bfe96",
            "ba28189ebbb1425c8417e9487a57c9a5",
            "8b60fb03a4e14c7e98267dba8bd8e645",
            "5631450297cb4d60ab95276a2ff49534",
            "7634f2ac12ab4141bf068a58efbb65cb",
            "e52661a17920406d878ed937be22cc0c",
            "6c2b667aef9e42c1be8d4c421da13559",
            "ee2398e915a14900b4e3192f55631329",
            "8ec3c5c2f4ef4fb18f9d60523a694226",
            "a6bf28f7fdd3428fa1e62db0fb20657d",
            "d7bdb295eba14456ab3ad7aa14dd17c6",
            "a6262c5d264141a1b0ec58553b03ccf9",
            "ce05de94d2f44c8aacafbb5b352fa0b8",
            "3b60514627a044fa9b3105af74202781",
            "ab47a893693a44f5948d1fe9dc4d544c",
            "19214740dff6405483969acb8494b7a3",
            "67fd8242e8fb499fa3e1898026d5e7ad",
            "7e5f68c2b77c4a738487549dbfb493ce",
            "6f83015384d94a1095cede0a526d3e0b",
            "72a03975621843e48312a9dfdb9ca094",
            "82fd9380d07f44da9c755868e153f6af",
            "696dbc69e46f4c54a70f75b47fe933b8",
            "3d741b597616418eb8fa62177405b9fa",
            "dc2dedc8aebd43a49a7a5cb587bec3b5",
            "4c6af0788bde4a7c97ec887ae52c84ac",
            "a96965d89fa549898400fcf491bc1116",
            "0451604ddcf942d099ebf561db919621",
            "f18db59f01264190a18d10201d25fc44",
            "290ef70b458d4feeafac3bcb94bb3584",
            "1f69920eaca5478da63104034906db0a",
            "c2434454e57543af9eea8a2492dfc0ce",
            "2b74d9a494524cf5b85d67ac97342b2c",
            "6799c71fc002485f8792b05c8db7e852",
            "2fc3a95fedbe44ab8767f786631d3b43",
            "3be9f3e4ea4d4d67ac835d21c5678dcf",
            "80c4cff4af8b427d93cb83ccb721e05a",
            "c7f2cd3a92ff48808a2b1af0d9142391",
            "19f42b2cf4dd4486b898671996b23fdc",
            "54ae82e5a83b4daf8b5b2ce1c9b75e39",
            "1936212cf4ec4cc68cd17e94128d96f1",
            "ee81c6133de04563874dbbb64ec1aa59",
            "901c9a6e39e04424b2c2fdb95307c91d",
            "7c0d5d71f2884b94a12f41c3fc7298a7",
            "ee244bc60c554848a96892b0ecb701db",
            "256681f5b8e24c89a5111da0ec5c37f2",
            "a906bb8283824e9097d36d05312bd306",
            "c9cd2a678bfa43a6a7b8b4c7c9ff45f1",
            "6f157af57a8f414ebe082f62953484f3",
            "4defa9a35ff0455eae2ee61c8ff049c9",
            "08b73c9a48534cddb7201ac41ea0eacf",
            "e762d52b0526404994aeb7c4552c17fb",
            "90cd4fa772db444c9ba97a553f442958",
            "8b010ab798c948949f0c79481aa45f50",
            "79eaddf75c70456ebaf05b89583b936a",
            "3288ca36d2f6445c9c36827639e228cb",
            "710ba80dcd2b4ae5acea5cd8512f24bc"
          ]
        },
        "id": "2VyGuAD_3y8N",
        "outputId": "f05990fc-0014-4961-eca5-96af38264b83"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3508908ab8c24163a17a1b379b0ca759"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb0b08915b4a4e82a85b2ffa7c03baa7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "145fdebe9d2a48f2a42b3fc32b2f49f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c78356fdae574ac080ca58b5956a8153"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2887979cbd914f089f2566f83575191d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "679f3f024cd347b79ddb1ce0722f49c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba28189ebbb1425c8417e9487a57c9a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce05de94d2f44c8aacafbb5b352fa0b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc2dedc8aebd43a49a7a5cb587bec3b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3be9f3e4ea4d4d67ac835d21c5678dcf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a906bb8283824e9097d36d05312bd306"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
      ],
      "metadata": {
        "id": "enDKAj-N4S5u"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('HUGGINGFACEHUB_API_TOKEN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "krfHBcO55aCc",
        "outputId": "0e40b87d-4004-4786-aad8-53c4661b817c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install chromadb"
      ],
      "metadata": {
        "id": "TWXniBSg4YNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "XF1i0SR24gbH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorStore = Chroma.from_documents(chunks, embedding)"
      ],
      "metadata": {
        "id": "OBVN51w047cS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarityRetriever = vectorStore.as_retriever(search_type = \"similarity\", search_kwargs = {\"k\": 3})"
      ],
      "metadata": {
        "id": "ivpRG-F25_Nf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39hBXvyJ6PTh",
        "outputId": "e4259fc4-98cc-4f5b-9c7c-06bbf3573912"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank_bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import BM25Retriever"
      ],
      "metadata": {
        "id": "Lk8qOL7h6U1h"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywordRetriever = BM25Retriever.from_documents(chunks)\n",
        "keywordRetriever.k = 3"
      ],
      "metadata": {
        "id": "5TAiGGC86hQy"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_retrieve(\n",
        "    query,\n",
        "    denseRetriever,\n",
        "    sparseRetriever,\n",
        "    denseWeight=0.5,\n",
        "    sparseWeight=0.5,\n",
        "    rrf_k=60\n",
        "):\n",
        "    scores = {}\n",
        "\n",
        "    # Dense retrieval\n",
        "    denseDocs = denseRetriever.invoke(query)\n",
        "    for rank, doc in enumerate(denseDocs):\n",
        "        key = doc.page_content\n",
        "        scores[key] = scores.get(key, 0) + denseWeight / (rank + 1 + rrf_k)\n",
        "\n",
        "    # Sparse retrieval\n",
        "    sparse_docs = sparseRetriever.invoke(query)\n",
        "    for rank, doc in enumerate(sparse_docs):\n",
        "        key = doc.page_content\n",
        "        scores[key] = scores.get(key, 0) + sparseWeight / (rank + 1 + rrf_k)\n",
        "\n",
        "    # Sort by final score\n",
        "    ranked_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return [doc for doc, _ in ranked_docs]\n"
      ],
      "metadata": {
        "id": "eLye74gS8RHi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"WHAT ARE THE DIFFERENCES IN THE UNINSURED RATE BY STATE IN 2022\"\n",
        "\n",
        "results = hybrid_retrieve(\n",
        "    query=query,\n",
        "    denseRetriever=similarityRetriever,\n",
        "    sparseRetriever=keywordRetriever,\n",
        "    denseWeight=0.5,\n",
        "    sparseWeight=0.5\n",
        ")\n",
        "\n",
        "for i, r in enumerate(results):\n",
        "    print(f\"{i+1}. {r[:100]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3xihemP8m13",
        "outputId": "fc7068a2-bb3f-427b-c6f8-cc0ee7284595"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. decreases (Appendix Table B-2). \n",
            "DIFFERENCES IN THE \n",
            "UNINSURED RATE BY STATE \n",
            "IN 2022\n",
            "In 2022, unins\n",
            "2. CHANGES IN THE UNINSURED \n",
            "RATE BY STATE FROM 2021 \n",
            "TO 2022\n",
            "From 2021 to 2022, uninsured rates \n",
            "decre\n",
            "3. percent), and New Mexico had \n",
            "the highest (Figure 4). \n",
            "\u2022 Twenty-seven states had lower \n",
            "uninsured ra\n",
            "4. Medicaid coverage was 22.7 per-\n",
            "cent in the group of states that \n",
            "expanded Medicaid eligibility and \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "S_Zy_lg1ReQE"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "k_rgNtP-SKnE"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace, HuggingFacePipeline\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id = \"Qwen/Qwen3-4B-Instruct-2507\",\n",
        "    task = \"text-generation\",\n",
        ")\n",
        "model = ChatHuggingFace(llm = llm)\n"
      ],
      "metadata": {
        "id": "bR6rRrN4QSj9"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "similarityPrompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    Answer the question using only the context below.\n",
        "    Context:\n",
        "    {context}\n",
        "    Question:\n",
        "    {question}\n",
        "    \"\"\",\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "similarityChain = (\n",
        "    {\n",
        "        \"context\": lambda x: \"\\n\\n\".join(\n",
        "            doc.page_content\n",
        "            for doc in similarityRetriever.invoke(x[\"question\"])\n",
        "        ),\n",
        "        \"question\": RunnablePassthrough()\n",
        "    }\n",
        "    | similarityPrompt\n",
        "    | model\n",
        "    | parser\n",
        ")\n"
      ],
      "metadata": {
        "id": "9x0S_Gm5RA7f"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response1 = similarityChain.invoke({\n",
        "    \"question\": \"WHAT ARE THE DIFFERENCES IN THE UNINSURED RATE BY STATE IN 2022\"\n",
        "})\n",
        "response1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "8LR_6om6SOv2",
        "outputId": "8c261851-ccae-4e07-a0b2-4a2855117793"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The differences in the uninsured rate by state in 2022 ranged from a low of 2.4 percent to a higher rate in New Mexico, which had the highest uninsured rate (Figure 4). Twenty-seven states had lower uninsured rates in 2022 compared to 2021, while Maine was the only state whose uninsured rate increased.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparsePrompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    Answer the question using only the context below.\n",
        "    Context:\n",
        "    {context}\n",
        "    Question:\n",
        "    {question}\n",
        "    \"\"\",\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "sparseChain = (\n",
        "    {\n",
        "        \"context\": lambda x: \"\\n\\n\".join(\n",
        "            doc.page_content\n",
        "            for doc in keywordRetriever.invoke(x[\"question\"])\n",
        "        ),\n",
        "        \"question\": RunnablePassthrough()\n",
        "    }\n",
        "    | similarityPrompt\n",
        "    | model\n",
        "    | parser\n",
        ")\n"
      ],
      "metadata": {
        "id": "Y4lBvLtuXANb"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = sparseChain.invoke({\n",
        "    \"question\": \"WHAT ARE THE DIFFERENCES IN THE UNINSURED RATE BY STATE IN 2022\"\n",
        "})\n",
        "response2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qSipeKjJXQ27",
        "outputId": "4dc5bc03-1f58-4e4b-f26a-9182a39fb560"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In 2022, uninsured rates at the time of interview ranged across states from a low of 2.4 percent.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hybridPrompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "Answer the question using the hybrid-retrieved context below.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\"\"\",\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "hybridChain = (\n",
        "    {\n",
        "        \"context\": lambda x: \"\\n\\n\".join(\n",
        "            hybrid_retrieve(\n",
        "                x[\"question\"],\n",
        "                similarityRetriever,\n",
        "                keywordRetriever\n",
        "            )\n",
        "        ),\n",
        "        \"question\": RunnablePassthrough()\n",
        "    }\n",
        "    | hybridPrompt\n",
        "    | model\n",
        "    | parser\n",
        ")\n"
      ],
      "metadata": {
        "id": "41KOWD4RXa8M"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response3 = hybridChain.invoke({\n",
        "    \"question\": \"WHAT ARE THE DIFFERENCES IN THE UNINSURED RATE BY STATE IN 2022\"\n",
        "})\n",
        "response3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "GNHDwZLuXiOl",
        "outputId": "4026afbb-4794-472a-f550-4b74d5dec7ec"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In 2022, the uninsured rates varied across states, ranging from a low of 2.4 percent to a higher rate in New Mexico, which had the highest uninsured rate (specific value not provided in the context). The exact rates for each state are not fully detailed, but it is noted that the uninsured rate in Maine increased from 2021 to 2022, while 27 states experienced a decrease in their uninsured rates. The specific values beyond the low of 2.4 percent and the high in New Mexico are not explicitly listed in the provided context.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}