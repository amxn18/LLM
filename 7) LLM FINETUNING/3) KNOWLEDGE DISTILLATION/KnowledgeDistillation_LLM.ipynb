{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kAoy4bDKwPi"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade datasets fsspec transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "rPnKaZ0SSCTV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchSize = 16\n",
        "lr = 5e-5\n",
        "epochs = 3\n",
        "temperature = 2.0\n",
        "alpha = 0.5\n",
        "maxLen = 128\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "wJCh-liNR7pa"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw = load_dataset(\"tweet_eval\", \"sentiment\")\n",
        "labelFeatures = raw[\"train\"].features[\"label\"]"
      ],
      "metadata": {
        "id": "1KukaRC1TStR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Label Name:\", labelFeatures.names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b00JAgNTTkUc",
        "outputId": "21298cd2-1e06-4a97-a8ed-cfb5dfa82e3a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Name: ['negative', 'neutral', 'positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainData = raw[\"train\"].shuffle(seed = 42).select(range(2500))\n",
        "validationData = raw[\"validation\"]"
      ],
      "metadata": {
        "id": "qOm_Fx4sTuqB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "17ccc056c60443beaf7dab72beb743d0",
            "9cfa27a3a6784d1db382e11744c54d34",
            "15951e023fc84774976def19baba0e8f",
            "88605421461d4fbf9a3afe70ffa2719d",
            "f0e173ae50964bb8a6552ad14aeb4bbc",
            "b4093d7fcab34872bd45af5d8d445f0a",
            "c9b827f7b2c347c48b2e4cef87a70cdd",
            "d1d36a97214141f79f6441b458f4cce0",
            "f9dcf8ee59804eb287bd63ac122daf4c",
            "ea43c172f4894cbca4d266b288663a6c",
            "87003bc5012641b0bcbb9c22c5aca52b",
            "c96bcc00c05346a0918e8639f91d0266",
            "69518aec62db45ef9ab2d873beb83f8f",
            "8dbb43b78ec446b793522de984beaa75",
            "fbf6df8d9d7043cf95c6646e9ed57c5c",
            "868a780649474c68ad41bb581bf14942",
            "7cb281235cad445eb52def18007d49ea",
            "1b0444fe8de340c2bc73d3534db5757c",
            "e9589e43e4e140659bd4f1e15783a437",
            "8e3feee09e1543aab2a541a07b4ca705",
            "8f1c70d23d974fc3adadc27fb3b0af34",
            "f20ebbdbf2fd4a60b01b63775dfc68c4",
            "eb6b4d08ab4b4f10aab40ec9703332b6",
            "a3b5bdb8cbc44302881a918958a74291",
            "2eeb148711294867bb966f1f976a5ffe",
            "19f7f3010d344bd6a8f5d9d1c4e9c62c",
            "0c49a4b20a52438db305f220f94caafd",
            "23bff41fb9f941dbbc659943991ec805",
            "5309ef39ebca44c3acfbdf0e0952e9da",
            "6a313065f9124622ada2366c7c7a215f",
            "deba1c644d804f7e9e9d202625dff0c3",
            "dbc979bd2bd64af583ad54a2e175ea17",
            "b25f59189fb541b38fe2f4ddbd9a2b28",
            "8636312e677a4cf2af76cafa2619aa76",
            "21a9fbe04e79434f967b4a42013bb6a9",
            "d0e8fad4f0154393bb117d00e8c34a67",
            "eca4e08d60fc4f8c9cb2befe4f054b1c",
            "5da0d098d2b3410c8c2c6f86525ca870",
            "8ad58ec8bacb4204b9344031a67ca51e",
            "5a648bd8cb7b457aaef7a69b91a0f3e2",
            "03fecbd3736d4213a0f28a8d4f360c1b",
            "f01d5e1a4e354821967edd79a152c198",
            "1684af92722d479db45ec826990bb669",
            "8b115ed5769f4f81b56db74def313220"
          ]
        },
        "id": "8zV6u-vtUM1K",
        "outputId": "5573d10b-66ca-46eb-f16e-06d8a34ce0fe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17ccc056c60443beaf7dab72beb743d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c96bcc00c05346a0918e8639f91d0266"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb6b4d08ab4b4f10aab40ec9703332b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8636312e677a4cf2af76cafa2619aa76"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(example):\n",
        "  return tokenizer(example[\"text\"], truncation = True, max_length=maxLen)\n",
        "\n",
        "tokenized = {}\n",
        "tokenized['train'] = trainData.map(tokenize, batched = True, remove_columns = ['text'])\n",
        "tokenized['validation'] = validationData.map(tokenize, batched = True, remove_columns = ['text'])"
      ],
      "metadata": {
        "id": "QBoktmTFUD-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaYq7HorVMWm",
        "outputId": "b98a600a-b2aa-4538-c0f8-0a9f4d556e35"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': Dataset({\n",
              "     features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "     num_rows: 2500\n",
              " }),\n",
              " 'validation': Dataset({\n",
              "     features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "     num_rows: 2000\n",
              " })}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collator = DataCollatorWithPadding(tokenizer = tokenizer, pad_to_multiple_of=8)\n",
        "trainingD1 = DataLoader(tokenized[\"train\"], batch_size= batchSize, shuffle=True, collate_fn=collator)\n",
        "validationD1 = DataLoader(tokenized[\"validation\"], batch_size= batchSize, shuffle= False, collate_fn= collator)"
      ],
      "metadata": {
        "id": "hHV5m9CgVbun"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "labels = 3\n",
        "teacherModel = AutoModelForSequenceClassification.from_pretrained(\"bert-large-uncased\", num_labels = labels).to(device)\n",
        "studentModel = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = labels).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776,
          "referenced_widgets": [
            "5161b62d453b4a7eabbadd1711079880",
            "791a5a4fcd354f7dafc073da3ba1f54a",
            "12e2cce0e8604e9cafcbc61606320748",
            "097064beca004c079efe6298c9fa3345",
            "67080ab218e743fdad10218958f9ef9c",
            "1f8aba2fde524be9a3a72542fcbc9c05",
            "217d502b4cf840e383f7942a08f8b74f",
            "29f648148bfd42928578f2018a5a9654",
            "bbee5fefd5ba40ffa07c3d8698c6ffd9",
            "44c11af99494453bb43d70a0145418f0",
            "d7ae20df123e4db58553a49db52a94ff",
            "d45efb1f3cac44b4933214d6b45466fe",
            "1f369d75eb784298a29c7a2e153c8a11",
            "1bebe7666a0942e6a584068ffc3bd869",
            "1220428394a84a24ac1f87360c2f95b1",
            "3c8292977cb74e92bb2db69e31065703",
            "4a24c9654bf542359ee593125fac57ee",
            "e93eecd154b84a0582be213497eb7995",
            "38cfb9e7ccba43b99aeb25a201cc81ca",
            "a0c9eb6db94546e79a2438929005ef51",
            "cb644296ee82450da4d1774590bc7a1c",
            "8e4148692fd749a49971151faa456872",
            "ad73c946d2c94d33809f528fa2e1a22f",
            "9e84b6a6640c46a6920c5856c40d07a5",
            "5448077bb46748a7b323bd5480954692",
            "0d4f19fc73054f0ab8937b1278262041",
            "0d5d94bace5040019fee964fcdac8a2d",
            "70d360b30c17453dbd76f127d7e8b943",
            "6cf58130267142ab9341bb638eca4ad3",
            "408a21c8790841c1b66e0d59edf4eb44",
            "4ad1d10aa29b438db4aed566db085f9a",
            "909aabf80e0a4957aa7fd3ef9013441c",
            "c324639d6f094522acd221909782760e",
            "ea8fdf75d0054b4ab9daa6722a0fab0f",
            "5005eea1a27c4cc5aa32d1cbfed1496b",
            "ae61edcdee8f4a9bad3ada688fdf0ee2",
            "c2c23eb99837440688c3cb4f9d0097d6",
            "e32716b6cdfd4406aa7e47d861ee859c",
            "0e46bcd359ae42118806f0617c152db1",
            "2daebf255af0406f82a362557581ea2e",
            "98256b7ac7eb4989b2430a40fe192f63",
            "32a0522bf8ef478b9ba5d91805703c64",
            "0cdb615eb755407a905156bd63e2ad5b",
            "8207b24b1805427e987c3562331cadbd",
            "f80c296602a640879f7b84c027e968b9",
            "8d838d29ccea4a70b084b7a48cd586eb",
            "7fad536d66b24b5a94f3e30059e77aed",
            "b8f717fa128d412eba613f257715c086",
            "ffde78e85a98463c844c4921cc459b33",
            "513dd341120e4a88a04da69522a0812f",
            "9daf38c1bb664c3caa7e52fe52f1f6f2",
            "c3d123a675614793adb004a01685e939",
            "6525ddf3b6b44319a6b77754c32d5b3f",
            "79589df5811f4c0bb317c86c89b642fc",
            "4cd83999c6834baba821fcc14e196796"
          ]
        },
        "id": "MXTQdEm2WZQK",
        "outputId": "0904c551-328d-4b73-9681-8411a7717bb4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5161b62d453b4a7eabbadd1711079880"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d45efb1f3cac44b4933214d6b45466fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad73c946d2c94d33809f528fa2e1a22f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: bert-large-uncased\n",
            "Key                                        | Status     | \n",
            "-------------------------------------------+------------+-\n",
            "cls.seq_relationship.bias                  | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
            "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
            "cls.predictions.bias                       | UNEXPECTED | \n",
            "cls.seq_relationship.weight                | UNEXPECTED | \n",
            "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
            "classifier.bias                            | MISSING    | \n",
            "classifier.weight                          | MISSING    | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea8fdf75d0054b4ab9daa6722a0fab0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f80c296602a640879f7b84c027e968b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: bert-base-uncased\n",
            "Key                                        | Status     | \n",
            "-------------------------------------------+------------+-\n",
            "cls.seq_relationship.bias                  | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
            "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
            "cls.predictions.bias                       | UNEXPECTED | \n",
            "cls.seq_relationship.weight                | UNEXPECTED | \n",
            "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
            "classifier.bias                            | MISSING    | \n",
            "classifier.weight                          | MISSING    | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacherModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ygw5H44nXCp1",
        "outputId": "f627d6a9-e487-4138-9641-e08727819e89"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "studentModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQMz6WdBXA_A",
        "outputId": "6bb42598-ee60-4a34-b862-f007287f4367"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freezing Teacher Model\n",
        "for p in teacherModel.parameters():\n",
        "  p.requires_grad = False\n",
        "\n",
        "teacherModel.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2IWPCTqXEyB",
        "outputId": "5ea516ad-24e0-4e28-cb4e-e86b71d312db"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crossEntropyLoss = nn.CrossEntropyLoss()\n",
        "KLLoss = nn.KLDivLoss(reduction = \"batchmean\")\n",
        "optimizer = optim.Adam(studentModel.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "DPgMq9zoXQwX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler\n",
        "lrScheduler = get_scheduler(\n",
        "    name = \"linear\",\n",
        "    optimizer = optimizer,\n",
        "    num_warmup_steps = 0,\n",
        "    num_training_steps = epochs * len(trainingD1)\n",
        ")"
      ],
      "metadata": {
        "id": "qbfa4doEX_l3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrScheduler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V2n7VzNYQ1L",
        "outputId": "1397a186-b5da-485a-f535-be0cefeeedca"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.optim.lr_scheduler.LambdaLR at 0x7c010bb1a000>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "def distillation():\n",
        "  studentModel.train()\n",
        "  pbar = tqdm(trainingD1, desc = \"Train\")\n",
        "  for batch in pbar:\n",
        "    inputIds = batch[\"input_ids\"].to(device)\n",
        "    attentionMask = batch[\"attention_mask\"].to(device)\n",
        "    labels = batch[\"labels\"].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      teacherLogits = teacherModel(inputIds, attentionMask).logits\n",
        "      teacherProbs = torch.softmax(teacherLogits/temperature, dim = -1)\n",
        "\n",
        "    studentLogits = studentModel(inputIds, attentionMask).logits\n",
        "    studentProbs = torch.log_softmax(studentLogits/temperature, dim = -1)\n",
        "\n",
        "\n",
        "    hardLoss = crossEntropyLoss(studentLogits, labels)\n",
        "    softLoss = KLLoss(studentProbs, teacherProbs) * (temperature**2)\n",
        "\n",
        "    loss = alpha*(hardLoss) + (1-alpha)*(softLoss)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    lrScheduler.step()\n",
        "    pbar.set_postfix({\"loss\": f\"{loss.item():.3f}\"})"
      ],
      "metadata": {
        "id": "74hkQp1iYSSd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate():\n",
        "  studentModel.eval()\n",
        "  correct, total = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for batch in validationD1:\n",
        "      ids = batch[\"input_ids\"].to(device)\n",
        "      attn = batch[\"attention_mask\"].to(device)\n",
        "      labels = batch[\"labels\"].to(device)\n",
        "      output = studentModel(ids, attn).logits\n",
        "      prediction = output.argmax(dim = 1)\n",
        "      correct += (prediction == labels).sum().item()\n",
        "      total += len(labels)\n",
        "  return round(correct/total * 100, 2)"
      ],
      "metadata": {
        "id": "j5AJJGMPZkMj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs+1):\n",
        "  distillation()\n",
        "  accuracy = evaluate()\n",
        "  print(f\"Epoch: {epoch}/{epochs} Accuracy: {accuracy}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "6d05ba974bd0411d9ae78da08626f5fd",
            "be13ca60745045a0b0b367ce0aefe762",
            "10c8889c451541c6889a6b72f1502402",
            "3b9c22074aaa44048a3cff4ea7ec54ab",
            "47fab8814b064e67a16a1fac80403981",
            "8d5b01c7e4514bd8b807aef77a54603c",
            "f5440e415dc1402e8574877d31b60d20",
            "e7e67e825daa450989511a3c517bed24",
            "a377263ef5ec498ea416e5f851f6ee3b",
            "c0f51f92075b4516abeb4064aaed84e3",
            "91359bfec710471fa8e31e1e3f31e6ba",
            "71eda9b52679415da8e1a8a4c8ada849",
            "a379b78383b446b7b72639c15b844596",
            "3617da7a5a5d4edebd45a25b69a79e9b",
            "d4cc2f2dd4da4bd8903c14248290dde2",
            "3d8425675c3f4931adf4a2b0581b38b4",
            "5b3637df0dc94afc917469bf0f79caf8",
            "8a4efa5760cd41ca9e282998608c8cd1",
            "dcbe4a83ca4543698f658580d3b586ac",
            "972d5ea0533649d29707458cbb8cd949",
            "b43654dfdb0c40438a1c8df81ae324c4",
            "8750b9fe964940fdb8b07df9b190f7f8",
            "8eb5049dc7164af1bc318d468dbdadea",
            "9ea6f890332c4fe2a867077908816a3a",
            "04ddd2ba7f114725b1e6560229f0de9d",
            "b2ad3519cc47499e85a215a814a494a1",
            "bdefb80454b44cf9a706d82b5eac66f6",
            "7e6112b9c1e24b778d8f9697a78e670e",
            "e5e2707a28304ad7b33ed24e7f92799a",
            "2ca5dba8ba7344fea4e13bff22b079ef",
            "740bc79f1413409ea165629edd187e9c",
            "d3e614d0da704c40980468678989cc20",
            "32dfe22f6a3d4b5d87ee6d348892fc95"
          ]
        },
        "id": "OZatLrIsZyyu",
        "outputId": "7ec9f95f-6d02-4ceb-9b1a-cfeab44a271d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d05ba974bd0411d9ae78da08626f5fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/3 Accuracy: 65.15%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71eda9b52679415da8e1a8a4c8ada849"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2/3 Accuracy: 65.15%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8eb5049dc7164af1bc318d468dbdadea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3/3 Accuracy: 65.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "studentModel.save_pretrained(\"distelledStudentModel\")\n",
        "tokenizer.save_pretrained(\"distelledStudentModel\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "44da4321ddbd433db0ad457200762e8d",
            "6a638eea34204d1791d94c1c0960ce83",
            "1b91c302c50942f59ab6492ec0cd0de4",
            "bedf6b9488184c38ab8e121a27574130",
            "1f8d4b3291994b7aa384ae37bf88fd0a",
            "477303325a394c8c9f8f430d176c537b",
            "4bc29cd89d8e4e8498ff385a15401e01",
            "e1771cf08474476eb63392c0cc463032",
            "523adb43bb5d4b1cbe76b6e37a3e57cc",
            "2b4aa9c152fb450e8e096cd0ed54b078",
            "0c8d5c4af34645f89ecabe38defa37a4"
          ]
        },
        "id": "Pfej8s1JbsFe",
        "outputId": "20f72ff0-579a-4587-e320-cf00caad3be1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44da4321ddbd433db0ad457200762e8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('distelledStudentModel/tokenizer_config.json',\n",
              " 'distelledStudentModel/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testingData = load_dataset(\"tweet_eval\", \"sentiment\", split = \"test[:500]\")\n",
        "tokenizedTest = testingData.map(tokenize, batched = True, remove_columns = [\"text\"])\n",
        "testingD1 = DataLoader(tokenizedTest, batch_size = batchSize, shuffle = False, collate_fn = collator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "52a1521c0c284557bff4e0fcc1778166",
            "93c416ca534940b49742a6197911063c",
            "fa044dca590e49f1a62cfd6e56887cc1",
            "82d511656f554cd99fa424bb287c3cfc",
            "6927683e155b4d35ba48643269311db2",
            "5a560ea7e0df4b7398735f9745f521e2",
            "c8113b6d65db477f9661387d7ac3d2f4",
            "4f9489c772cd4ddcb01996a92fa46659",
            "8d0c22c6da4743b69ffbc8c55768dab7",
            "b51b94fe41c54a5c8518e74dec5a7591",
            "6a4b56897f794d268a412089e2910b37"
          ]
        },
        "id": "SfaS_CG1b-Dv",
        "outputId": "8bfadcc0-4bc5-4502-abd3-7cc3f6082bb5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52a1521c0c284557bff4e0fcc1778166"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def PredictionAndEvaluation(model, name, testingD1):\n",
        "    model.eval()\n",
        "    preds, all_labels = [], []\n",
        "    start = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in testingD1:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            attn = batch[\"attention_mask\"].to(device)\n",
        "            batch_labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            logits = model(ids, attention_mask=attn).logits\n",
        "            prediction = logits.argmax(dim=1)\n",
        "\n",
        "            preds.extend(prediction.cpu().tolist())\n",
        "            all_labels.extend(batch_labels.cpu().tolist())\n",
        "\n",
        "    totalTime = time.time() - start\n",
        "    accuracy = accuracy_score(all_labels, preds)\n",
        "\n",
        "    avgTime = totalTime / len(testingD1.dataset)\n",
        "\n",
        "    print(f\"\\n{name}\")\n",
        "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
        "    print(f\"Total Inference Time: {totalTime:.4f} seconds\")\n",
        "    print(f\"Average Time per Sample: {avgTime:.6f} seconds\")\n",
        "\n",
        "    return accuracy, totalTime, avgTime"
      ],
      "metadata": {
        "id": "63HQNxAUcWD2"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PredictionAndEvaluation(teacherModel, \"Teacher Model\", testingD1)\n",
        "PredictionAndEvaluation(studentModel, \"Distilled Student Model\", testingD1)"
      ],
      "metadata": {
        "id": "r6ceaiUydfdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLM"
      ],
      "metadata": {
        "id": "VPRUbUZdqMtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "-gheZaReqGpL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig, BitsAndBytesConfig"
      ],
      "metadata": {
        "id": "wkurntX6t2eH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoConfig"
      ],
      "metadata": {
        "id": "I-0CqCMlrbun"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacherModelID = \"microsoft/phi-2\"\n",
        "studentModelID = \"microsoft/phi-1_5\""
      ],
      "metadata": {
        "id": "PZA9XMUOqdQf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacherTokenizer = AutoTokenizer.from_pretrained(teacherModelID)\n",
        "studentTokenizer = AutoTokenizer.from_pretrained(studentModelID)\n",
        "\n",
        "if teacherTokenizer.pad_token is None:\n",
        "    teacherTokenizer.pad_token = teacherTokenizer.eos_token\n",
        "\n",
        "if studentTokenizer.pad_token is None:\n",
        "    studentTokenizer.pad_token = studentTokenizer.eos_token"
      ],
      "metadata": {
        "id": "MUE29HKmrAqu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnbConfig = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")"
      ],
      "metadata": {
        "id": "FbTU6iQ1uEwp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacherConfig = AutoConfig.from_pretrained(teacherModelID)\n",
        "teacherConfig.pad_token_id = teacherTokenizer.eos_token_id\n",
        "\n",
        "teacherModel = AutoModelForCausalLM.from_pretrained(\n",
        "    teacherModelID,\n",
        "    config=teacherConfig,\n",
        "    quantization_config=bnbConfig,\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61,
          "referenced_widgets": [
            "540994dd487748ac9c97fc6c11748121",
            "c0b6d1fe18d94da7b54abee49df9b593",
            "23872e10ddd8454ea67a064e7b70e04b",
            "bbdf327889c64b00ab2710e25f010864",
            "f3ffe8cf5f2e46bca8d768e2352eece2",
            "28eeaeffddac4ac7a8689e2fa9c4bc94",
            "c2cbfd22772f456f960e6886e596b198",
            "960bf7fb661f4a2684ed68143b5adb11",
            "e1982343bee4486eb89d51ac68426d06",
            "0f8e81cd726349928763c2819a6f3302",
            "65ac33407ab04cd3954a766227ede3cb"
          ]
        },
        "id": "7fuyLi-IuIAv",
        "outputId": "08f10c4b-e542-473e-f08d-681d95085903"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/453 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "540994dd487748ac9c97fc6c11748121"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "studentConfig = AutoConfig.from_pretrained(studentModelID)\n",
        "studentConfig.pad_token_id = studentTokenizer.eos_token_id\n",
        "\n",
        "studentModel = AutoModelForCausalLM.from_pretrained(\n",
        "    studentModelID,\n",
        "    config=studentConfig,\n",
        "    quantization_config=bnbConfig,\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61,
          "referenced_widgets": [
            "211a4ce404cf460183a7232525c18f10",
            "f3ab23a4a9af4f59a118c397c456172d",
            "5f6f03f0d79d4c7791b52245ffd25682",
            "93a95472176b460abd6673c06eafa27f",
            "15c96ec8c086484e947da9d0a83cdf58",
            "e150c9877a7a4176aa05c00b0c8d3048",
            "43bfea24ca244701916c8bea7b85885f",
            "f8677c0253294657b4cfd41685be6dd8",
            "756fceffd9a14d9788a62da2f28008f3",
            "6e728bb73de64f71bd96080b7004ccb3",
            "f2955139029048a1b065184d08a677cf"
          ]
        },
        "id": "AX0d8trIroyV",
        "outputId": "f0f90287-e9f5-4345-8401-6e3d25db02a6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/341 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "211a4ce404cf460183a7232525c18f10"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacherModel.eval()\n",
        "for p in teacherModel.parameters():\n",
        "    p.requires_grad = False"
      ],
      "metadata": {
        "id": "7eB34UOFuiWt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"Explain why the sky is blue. ### The sky appears blue because molecules in Earth's atmosphere scatter sunlight, and blue light is scattered more than other colors due to its shorter wavelength.\",\n",
        "    \"What is the capital of France? ### The capital of France is Paris.\",\n",
        "    \"Write a short story about a robot and a cat. ### Once upon a time, a lonely robot found a stray cat. They became best friends, exploring the city together, and the robot learned the meaning of companionship.\"\n",
        "]"
      ],
      "metadata": {
        "id": "c72pOLvDuOFP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temperature = 2.0\n",
        "alpha_soft  = 0.7\n",
        "CELoss     = nn.CrossEntropyLoss(ignore_index=studentTokenizer.pad_token_id)\n",
        "KLLoss     = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "optimizer   = optim.AdamW(studentModel.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "wFWY0T_2vCc-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts:\n",
        "    t_inputs = teacherTokenizer(prompt, return_tensors=\"pt\", padding=True).to(teacherModel.device)\n",
        "    s_inputs = studentTokenizer(prompt, return_tensors=\"pt\", padding=True).to(studentModel.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        t_logits = teacherModel(**t_inputs).logits[:, :-1, :]\n",
        "        t_soft = torch.softmax(t_logits / temperature, dim=-1)\n",
        "        t_soft = torch.clamp(t_soft, min=1e-8)\n",
        "\n",
        "    s_logits = studentModel(**s_inputs).logits[:, :-1, :]\n",
        "    s_log_soft = torch.log_softmax(s_logits / temperature, dim=-1)\n",
        "\n",
        "    labels = s_inputs[\"input_ids\"][:, 1:].contiguous()\n",
        "\n",
        "    loss_hard = CELoss(s_logits.reshape(-1, s_logits.size(-1)), labels.reshape(-1))\n",
        "    loss_soft = KLLoss(s_log_soft, t_soft) * (temperature ** 2)\n",
        "\n",
        "    loss = alpha_soft * loss_soft + (1 - alpha_soft) * loss_hard\n",
        "\n",
        "    if torch.isnan(loss):\n",
        "        print(\"NaN detected on prompt:\", prompt[:50])\n",
        "        continue\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Prompt: {prompt[:40]}..., Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "lbO2BMWHvcyq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}