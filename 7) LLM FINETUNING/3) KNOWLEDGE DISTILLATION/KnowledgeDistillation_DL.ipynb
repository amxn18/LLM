{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MmFenwXQhSrs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "hQgvGjMWjcmD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingData = datasets.MNIST(root = './data', train = True, transform=transform, download=True)\n",
        "testingData = datasets.MNIST(root = './data', train = False, transform=transform, download=True)\n",
        "\n",
        "trainingLoader = DataLoader(trainingData, batch_size=64, shuffle=True)\n",
        "testingLoader =  DataLoader(testingData, batch_size = 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQBqc-EQjsH1",
        "outputId": "e6c77078-23bb-4c49-b4e2-e72275a09d56"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9.91M/9.91M [00:01<00:00, 5.11MB/s]\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 28.9k/28.9k [00:00<00:00, 133kB/s]\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.65M/1.65M [00:01<00:00, 1.28MB/s]\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.54k/4.54k [00:00<00:00, 8.21MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TeacherModel(nn.Module):\n",
        "  def __init__(self, hidden1 = 512, hidden2 = 256):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(28*28, hidden1),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(hidden1, hidden2),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(hidden2, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "7siry9zfkFxy"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher = TeacherModel()"
      ],
      "metadata": {
        "id": "10ywtY79IE_D"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcNKZf4wIKfN",
        "outputId": "14e5eaa9-0dd7-45d8-ba4b-b72556f2b88f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TeacherModel(\n",
              "  (net): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def TeacherTraining(model, loader, epochs = 5, lr = 1e-3):\n",
        "  optimizer = optim.Adam(model.parameters(), lr = lr)\n",
        "  lossFunction = nn.CrossEntropyLoss()\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for epoch in range(epochs):  # Training loop\n",
        "    totalLoss = 0;\n",
        "    for x, y in loader:        # x--> input , y--> target\n",
        "      optimizer.zero_grad()\n",
        "      output = model(x)\n",
        "      loss = lossFunction(output, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      totalLoss += loss.item()\n",
        "    print(f\"Teacher Epoch {epoch + 1}: Loss = {totalLoss/len(loader):.4f}\")\n",
        ""
      ],
      "metadata": {
        "id": "TbZRTYoRIPA8"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TeacherTraining(teacher, trainingLoader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd8TpebAI-2s",
        "outputId": "c368c11b-0d38-4582-88f4-8ed064954d44"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Epoch 1: Loss = 0.3024\n",
            "Teacher Epoch 2: Loss = 0.1348\n",
            "Teacher Epoch 3: Loss = 0.0999\n",
            "Teacher Epoch 4: Loss = 0.0819\n",
            "Teacher Epoch 5: Loss = 0.0696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StudentModel(nn.Module):\n",
        "  def __init__(self, hidden = 128):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(28*28, hidden),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(hidden, 10)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "kJHtRDbAJogt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student = StudentModel()"
      ],
      "metadata": {
        "id": "PJEU-ymxKP0K"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* S1) Pretraining Student Model On Hard Labels"
      ],
      "metadata": {
        "id": "U9WA8zfIKt9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pretrainStudent(model, loader, epochs = 3, lr = 1e-3):\n",
        "  optimizer2 = optim.Adam(model.parameters(), lr = lr)\n",
        "  lossFunction = nn.CrossEntropyLoss()\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for epoch in range(epochs):  # Training loop\n",
        "    totalLoss2 = 0;\n",
        "    for x, y in loader:        # x--> input , y--> target\n",
        "      optimizer2.zero_grad()\n",
        "      output = model(x)\n",
        "      loss = lossFunction(output, y)\n",
        "      loss.backward()\n",
        "      optimizer2.step()\n",
        "      totalLoss2 += loss.item()\n",
        "    print(f\"Student Epoch {epoch + 1}: Loss = {totalLoss2/len(loader):.4f}\")"
      ],
      "metadata": {
        "id": "YFbO572nKZu-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrainStudent(student, trainingLoader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0cHPwlgLVDZ",
        "outputId": "4bd0f5d8-5ac0-488b-e1a7-dd38ec4198c5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Epoch 1: Loss = 0.3830\n",
            "Student Epoch 2: Loss = 0.2005\n",
            "Student Epoch 3: Loss = 0.1437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* S2) Distillation"
      ],
      "metadata": {
        "id": "rsn0_tK3LnKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperature = 2.0\n",
        "alpha = 0.7\n",
        "crossEntropyLoss = nn.CrossEntropyLoss()\n",
        "klDivergernceLoss = nn.KLDivLoss(reduction = 'batchmean')\n",
        "optimizer = optim.Adam(student.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "id": "n0WsGTaYLlbO"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distillation(student,teacher,loader,epochs=5,lr=1e-3):\n",
        "    teacher.eval()\n",
        "\n",
        "    studentOptimizer = optim.Adam(student.parameters(), lr=lr)\n",
        "\n",
        "    crossEntropyLoss = nn.CrossEntropyLoss()\n",
        "    KLDivergenceLoss = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        student.train()\n",
        "        totalLoss = 0\n",
        "        for x, y in loader:\n",
        "            with torch.no_grad():\n",
        "                teacherLogits = teacher(x)\n",
        "                teacherProbs = torch.softmax(teacherLogits / temperature, dim=1)\n",
        "\n",
        "            studentLogits = student(x)\n",
        "            studentLogProbs = torch.log_softmax(studentLogits / temperature, dim=1)\n",
        "\n",
        "            softLoss = KLDivergenceLoss(studentLogProbs,teacherProbs) * (temperature ** 2)\n",
        "            hardLoss = crossEntropyLoss(studentLogits, y)\n",
        "\n",
        "\n",
        "            loss = alpha * softLoss + (1 - alpha) * hardLoss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            totalLoss += loss.item()\n",
        "\n",
        "        print(f\"Student Epoch {epoch+1}: Loss = {totalLoss/len(loader):.4f}\")"
      ],
      "metadata": {
        "id": "lHCEl3h1MK7_"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distillation(student, teacher, trainingLoader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1nn1glBNFzS",
        "outputId": "717b7e79-b63d-4c5d-dd70-6f9ffff8924a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Epoch 1: Loss = 0.1922\n",
            "Student Epoch 2: Loss = 0.1323\n",
            "Student Epoch 3: Loss = 0.1090\n",
            "Student Epoch 4: Loss = 0.0972\n",
            "Student Epoch 5: Loss = 0.0907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model, loader, name = \"Model\"):\n",
        "  model.eval()\n",
        "  correct, total = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      output = model(x)\n",
        "      prediction = output.argmax(dim = 1)\n",
        "      correct += (prediction == y).sum().item()\n",
        "      total += y.size(0)\n",
        "\n",
        "  accuracy = correct / total * 100\n",
        "  print(f\"{name} Accuracy: {accuracy:.2f}%\")\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "i0B3f2R4QpY8"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(teacher, testingLoader, \"Teacher\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02QG_FGGTFij",
        "outputId": "e1c1d87c-468d-4979-c3ee-ca6f0afed231"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Accuracy: 97.05%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.05"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(student, testingLoader, \"Student\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SipFNRr7TIPU",
        "outputId": "b999891b-f9a3-4b9e-8b34-57f491c29514"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Accuracy: 97.12%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.11999999999999"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model, x):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    output = model(x)\n",
        "    return output.argmax(dim = 1)"
      ],
      "metadata": {
        "id": "8hrIWYmiTWPZ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampleBatch, sampleLabels = next(iter(testingLoader))\n",
        "predictions = prediction(student, sampleBatch)"
      ],
      "metadata": {
        "id": "_oFhSFbDTgNJ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Predicted Labels: {predictions[:10]}\")\n",
        "print(f\"Actual Labels: {sampleLabels[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X99ugPPETpda",
        "outputId": "3f8f789f-9a5f-49fe-be1c-72dd10d8f140"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])\n",
            "Actual Labels: tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(student.state_dict(), \"distilledDL.pth\")\n",
        "print(\"Saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25019AzGT2_d",
        "outputId": "c1f7f69c-0afb-4c45-8952-5a0a1226fbb6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved\n"
          ]
        }
      ]
    }
  ]
}