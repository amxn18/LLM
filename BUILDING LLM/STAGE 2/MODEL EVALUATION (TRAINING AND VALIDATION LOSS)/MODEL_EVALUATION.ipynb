{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation (Training and Validation Loss)"
      ],
      "metadata": {
        "id": "MXXwE0-gDrxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "6_MEp6ZEEioH"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "9GHwL4MfDbo4"
      },
      "outputs": [],
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding = \"utf-8\") as f:\n",
        "  rawtext = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "35ltqtPlE2c5"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rawtext[:100])\n",
        "totalChars = len(rawtext)\n",
        "print(totalChars)\n",
        "totalTokens = len(tokenizer.encode(rawtext))\n",
        "print(totalTokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnFOYQLvEQKI",
        "outputId": "161be87d-6f3c-4983-cb88-85a73dfe221c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n",
            "20479\n",
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\":256, # 1024-->256 (for local pc)\n",
        "    \"emb_dim\":768,\n",
        "    \"n_layers\":12,\n",
        "    \"n_heads\":12,\n",
        "    \"drop_rate\":0.1,\n",
        "    \"qkv_bias\": False\n",
        "}"
      ],
      "metadata": {
        "id": "hZfjY2m2FEIm"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'Layer Normalization'\n",
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps = 1e-5\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim =-1, keepdim= True) # Mean Along Column\n",
        "    var = x.var(dim =-1, keepdim= True, unbiased = False) # Variance Along Column\n",
        "    normalizedX = (x-mean)/torch.sqrt(var+self.eps)  # Eps is small constant to prevent dividing by 0 during normalization\n",
        "    return self.scale * normalizedX + self.shift\n",
        "\n",
        "# Scale and shift are two trainable params of same dim as input that LLM automatically adjusts during training and this improves models performance on its training task\n",
        "\n",
        "'GELU ACTIVATION FUNCTION'\n",
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return 0.5 * x * (1 + torch.tanh(\n",
        "        torch.sqrt(torch.tensor(2 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))\n",
        "    ))\n",
        "\n",
        "'Feed Forward Neural Network'\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(cfg[\"emb_dim\"], 4*cfg[\"emb_dim\"]), #Expansion\n",
        "        nn.GELU(), # Activation\n",
        "        nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"]), # Compression\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "E1ilLHudFHw3"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'Masked Self Attention'\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "qbaPZuoWFKtj"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'TRANSFORMER BLOCK'\n",
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.attention = MultiHeadAttention(\n",
        "        d_in = cfg[\"emb_dim\"],\n",
        "        d_out = cfg[\"emb_dim\"],\n",
        "        context_length = cfg[\"context_length\"],\n",
        "        dropout = cfg[\"drop_rate\"],\n",
        "        num_heads = cfg[\"n_heads\"],\n",
        "        qkv_bias= cfg[\"qkv_bias\"]\n",
        "    )\n",
        "    self.feedforwardNN = FeedForward(cfg)\n",
        "    self.normalization1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.normalization2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self, x):\n",
        "    shortcut = x\n",
        "    x = self.normalization1(x)\n",
        "    x = self.attention(x)  #Shape [batch_size, num_tokens, emb_size]\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = shortcut + x # Add the original input block\n",
        "\n",
        "    # Shortcut connection for feed forward block\n",
        "    shortcut = x\n",
        "    x = self.normalization2(x)\n",
        "    x = self.feedforwardNN(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = shortcut + x\n",
        "    return x"
      ],
      "metadata": {
        "id": "Oq4D1SPLFNZn"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.tokenEmbeddings = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "    self.positionalEmbeddings = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"]) #(1024x768)\n",
        "    self.dropuoutEmbeddings = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    'Transformer Block'\n",
        "    self.transformerBlock = nn.Sequential(\n",
        "    *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "   )\n",
        "    'Layer Normalization'\n",
        "    self.finalNormalization = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head = nn.Linear(\n",
        "        cfg[\"emb_dim\"],\n",
        "        cfg[\"vocab_size\"], bias = False\n",
        "    )\n",
        "\n",
        "  def forward(self, inIdx):\n",
        "    batchSize, seqLen  = inIdx.shape\n",
        "    tokenEmbeddings = self.tokenEmbeddings(inIdx)\n",
        "    positionalEmbeddings = self.positionalEmbeddings(torch.arange(seqLen, device = inIdx.device))\n",
        "    x = tokenEmbeddings + positionalEmbeddings\n",
        "    x = self.dropuoutEmbeddings(x)\n",
        "    x = self.transformerBlock(x)\n",
        "    x = self.finalNormalization(x)\n",
        "    logits = self.out_head(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "W2WtImBVFQN6"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateText(model, idx, maxNewTokens, contextSize):\n",
        "    # idx is (batch, numTokens) array of indices in the current context\n",
        "    for _ in range(maxNewTokens):\n",
        "        # Crop the current context if it exceeds the supported size\n",
        "        idxCond = idx[:, -contextSize:]\n",
        "\n",
        "        # Predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idxCond)  # (batch, numTokens, vocabSize)\n",
        "\n",
        "        # S1) Extract last vector\n",
        "        logits = logits[:, -1, :]  # (batch, vocabSize)\n",
        "\n",
        "        # S2) Apply softmax to get probabilities\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "        # S3) Choose the highest probability\n",
        "        idxNext = torch.argmax(probs, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # S4) Append the new token to the sequence\n",
        "        idx = torch.cat((idx, idxNext), dim=1)  # (batch, numTokens+1)\n",
        "\n",
        "    return idx\n"
      ],
      "metadata": {
        "id": "4GnGi4yHFXoy"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\":256, # 1024-->256 (for local pc)\n",
        "    \"emb_dim\":768,\n",
        "    \"n_layers\":12,\n",
        "    \"n_heads\":12,\n",
        "    \"drop_rate\":0.1,\n",
        "    \"qkv_bias\": False\n",
        "}\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dMrm9xpFfk-",
        "outputId": "c1f08f8c-e5aa-400c-e279-8cc99b811562"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tokenEmbeddings): Embedding(50257, 768)\n",
              "  (positionalEmbeddings): Embedding(256, 768)\n",
              "  (dropuoutEmbeddings): Dropout(p=0.1, inplace=False)\n",
              "  (transformerBlock): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (finalNormalization): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def textToTokenId(text, tokenizer):\n",
        "  encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "  encodedTensor = torch.tensor(encoded).unsqueeze(0) # Adding batch dimension\n",
        "  return encodedTensor\n",
        "def tokenIdtoText(tokenId, tokenizer):\n",
        "  flat = tokenId.squeeze(0) # Removing Batch dimension\n",
        "  return tokenizer.decode(flat.tolist())\n",
        "\n",
        "startContext = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "tokenIds = generateText(\n",
        "    model = model,\n",
        "    idx = textToTokenId(startContext, tokenizer),\n",
        "    maxNewTokens=10,\n",
        "    contextSize= GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output text:\\n\", tokenIdtoText(tokenIds, tokenizer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09_n24_aFYXv",
        "outputId": "f57d89d6-1fdb-4227-87d4-acd21bfa1978"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Dataset and DataLoader"
      ],
      "metadata": {
        "id": "FqS6nF-mFm4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self, txt, tokenizer, maxLen, stride):\n",
        "    self.ipIds = []\n",
        "    self.targetIds = []\n",
        "\n",
        "    # S1 --> Tokenize the Entire text\n",
        "    tokenIds = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "    # S2 --> Using sliding window to chunk book into overlapping sequence of maxLen\n",
        "    for i in range(0, len(tokenIds) - maxLen, stride):\n",
        "      inputChunk = tokenIds[i:i+maxLen]  # 0->4\n",
        "      targetChunk = tokenIds[i+1:i+1+maxLen] # 1->5\n",
        "\n",
        "      self.ipIds.append(torch.tensor(inputChunk))  # Input Tensor X\n",
        "      self.targetIds.append(torch.tensor(targetChunk)) # Target Tensor Y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ipIds)\n",
        "  def __getitem__(self, idx):\n",
        "    return self.ipIds[idx], self.targetIds[idx]  # Ip OP Pairs"
      ],
      "metadata": {
        "id": "d4jOi9-oFpNQ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataLoaderV1(txt, batch_size = 4, max_length = 256,\n",
        "                 stride = 128, shuffle = True, drop_last = True,\n",
        "                 num_workers = 0):\n",
        "  # S1) Initialize the tokenizer\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  # S2) Create Dataset\n",
        "  dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "  # S3) Create Dataloader\n",
        "  dataloader = DataLoader(dataset, batch_size = batch_size,\n",
        "                          shuffle = shuffle, drop_last = drop_last,\n",
        "                          num_workers = num_workers)\n",
        "  return dataloader\n"
      ],
      "metadata": {
        "id": "L0pygE3qFvFM"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Splitting Dataset"
      ],
      "metadata": {
        "id": "EDJ9CWObGL53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainRatio = 0.90\n",
        "splitIdx = int(trainRatio*len(rawtext))\n",
        "trainingData = rawtext[:splitIdx]\n",
        "validationData = rawtext[splitIdx:]\n",
        "\n",
        "torch.manual_seed(123)\n",
        "trainLoader = dataLoaderV1(\n",
        "    trainingData,\n",
        "    batch_size = 2,\n",
        "    max_length = GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride = GPT_CONFIG_124M[\"context_length\"],\n",
        "    shuffle = True,\n",
        "    drop_last = True,\n",
        "    num_workers = 0\n",
        ")\n",
        "\n",
        "validationLoader = dataLoaderV1(\n",
        "    validationData,\n",
        "    batch_size = 2,\n",
        "    max_length = GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride = GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last= False,\n",
        "    shuffle= False,\n",
        "    num_workers= 0\n",
        ")"
      ],
      "metadata": {
        "id": "X9e2nOXCGONo"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'Sanity Check'\n",
        "if totalTokens*(trainRatio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "  print(\"Not enough data for training\")\n",
        "if(totalTokens*(1-trainRatio)) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "  print(\"Not enough data for validation\")"
      ],
      "metadata": {
        "id": "HoFj4-JZHw5U"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Loader\")\n",
        "for x, y in trainLoader:\n",
        "  print(x.shape, y.shape)\n",
        "print(\"Validation Loader\")\n",
        "for x, y in validationLoader:\n",
        "  print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dob1EI0IDPP",
        "outputId": "4752fc86-16af-406d-ad66-f4563cd54bb3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loader\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "Validation Loader\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainingTokens = 0\n",
        "for inputBatch, targetBatch in trainLoader:\n",
        "  trainingTokens += inputBatch.numel()\n",
        "validationTokens = 0\n",
        "for inputBatch, targetBatch in validationLoader:\n",
        "  validationTokens += inputBatch.numel()\n",
        "print(\"Training Tokens: \", trainingTokens)\n",
        "print(\"Validation Tokens: \", validationTokens)\n",
        "print(\"Total Tokens:\", totalTokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmmSq_-NIhd-",
        "outputId": "e6f50c8e-6943-4de9-a378-de6e906e4a38"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Tokens:  4608\n",
            "Validation Tokens:  512\n",
            "Total Tokens: 5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Calclating Cross Entropy Loss"
      ],
      "metadata": {
        "id": "DOjpMHLgJDEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateLossBatch(inputBatch, targetBatch, model, device):\n",
        "  inputBatch, targetBatch = inputBatch.to(device), targetBatch.to(device)\n",
        "  logits = model(inputBatch)\n",
        "  loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), targetBatch.flatten(), ignore_index = 0)\n",
        "  return loss\n",
        "\n",
        "def calculateLossLoader(dataLoaderV1, model, device, num_batches = None):\n",
        "  totalLoss = 0\n",
        "  if(len(dataLoaderV1) == 0): return float(\"nan\")\n",
        "  elif num_batches is None: num_batches = len(dataLoaderV1)\n",
        "  else:\n",
        "    # Reduce the number of batches to match the total no of batches in data loader\n",
        "    num_batches = min(num_batches, len(dataLoaderV1))\n",
        "  for i, (inputBatch, targetBatch) in enumerate(dataLoaderV1):\n",
        "    if i< num_batches:\n",
        "      loss = calculateLossBatch(inputBatch, targetBatch, model, device)\n",
        "      totalLoss += loss.item()\n",
        "    else : break\n",
        "  return totalLoss/num_batches # Mean Loss per batch"
      ],
      "metadata": {
        "id": "KRV4TW5tJGpu"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "# NOTE: Connected to T4 GPU on COLAB thats why it is printing CUDA and execution time is less"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNbEFibwJd1d",
        "outputId": "5ebc9ba7-1795-4d2c-99b3-76557e29c37b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKWFoyR3KrAY",
        "outputId": "17bad4b3-96de-4365-ca0f-4b7fe27e0887"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tokenEmbeddings): Embedding(50257, 768)\n",
              "  (positionalEmbeddings): Embedding(256, 768)\n",
              "  (dropuoutEmbeddings): Dropout(p=0.1, inplace=False)\n",
              "  (transformerBlock): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feedforwardNN): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (normalization1): LayerNorm()\n",
              "      (normalization2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (finalNormalization): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "with torch.no_grad(): # Disabling gradient tracking for efficiency because we are not training yet\n",
        "  trainingLoss = calculateLossLoader(trainLoader, model, device)\n",
        "  validationLoss = calculateLossLoader(validationLoader, model, device)\n",
        "print(\"Training Loss: \", trainingLoss)\n",
        "print(\"Validation Loss: \", validationLoss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke0cAPxaKwjf",
        "outputId": "0b13cb69-d0ed-478b-bd6b-7519c329b58d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss:  10.98753579457601\n",
            "Validation Loss:  10.983574867248535\n"
          ]
        }
      ]
    }
  ]
}